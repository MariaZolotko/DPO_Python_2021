{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Центр непрерывного образования\n",
    "\n",
    "# Программа «Python для автоматизации и анализа данных»\n",
    "\n",
    "*Ян Пиле, Яндекс.Маркет*  \n",
    "\n",
    "# Задачки на регулярные выражения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задачка про аббревиатуры\n",
    "Владимир устроился на работу в одно очень важное место. И в первом же документе он ничего не понял, \n",
    "там были сплошные ФГУП НИЦ ГИДГЕО, ФГОУ ЧШУ АПК и т.п. Тогда он решил собрать все аббревиатуры, чтобы потом найти их расшифровки на http://sokr.ru/. Помогите ему.\n",
    "Будем считать аббревиатурой слова только лишь из заглавных букв (как минимум из двух). Если несколько таких слов разделены пробелами, то они \n",
    "считаются одной аббревиатурой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ввод**: Это курс информатики соответствует ФГОС и ПООП, это подтверждено ФГУ ФНЦ НИИСИ РАН\\\n",
    "**Вывод**: ФГОС, ПООП, ФГУ ФНЦ НИИСИ РАН"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ФГОС', 'ПООП', 'ФГУ ФНЦ НИИСИ РАН']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# Ваше решение\n",
    "s = 'Это курс информатики соответствует ФГОС и ПООП, это подтверждено ФГУ ФНЦ НИИСИ РАН'\n",
    "re.findall(r\"[А-ЯЁА-Я]{2,}(?:\\s+[А-ЯЁА-Я]{2,})*\", s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задачка про перевод из camel_case'a в snake_case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы уже довольно много говорили про то, что в компаниях могут быть конвенции по обозначению переменных. Что, если вы написали код, а в нем переменные названы в Camel Case а вам требуется snake case? Пожалуй, стоит автоматизировать этот процесс. Попробуем написать функцию, которая этот функционал реализует"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camel_case_var\n"
     ]
    }
   ],
   "source": [
    "#Camel case to snake case\n",
    "v = 'camelCaseVar'\n",
    "import re\n",
    "\n",
    "def Camel_to_Snake(text):\n",
    "\n",
    "    pattern=\"(\\B[A-Z])\"\n",
    "    repl=r\"_\\1\"\n",
    "    return (re.sub(pattern,repl,v)).lower()\n",
    "\n",
    "print(Camel_to_Snake(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задачка про подсчет количества слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Слова у нас могут состоять из букв или букв, стоящих вокруг дефиса (во-первых, чуть-чуть, давай-ка). Попробуем это описать регулярным выражением"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "['-', 'Дельный,', 'что', 'и', 'говорить,', 'Был', 'старик', 'тот', 'самый,', 'Что', 'придумал', 'суп', 'варить', 'На', 'колесах', 'прямо.', 'Суп', '-', 'во-первых.', 'Во-вторых,', 'Кашу', 'в', 'норме', 'прочной.', 'Нет,', 'старик', 'он', 'был', 'старик', 'Чуткий', '-', 'это', 'точно.']\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = '''\n",
    "                    - Дельный, что и говорить,\n",
    "                      Был старик тот самый,\n",
    "                      Что придумал суп варить\n",
    "                      На колесах прямо.\n",
    "                      Суп - во-первых. Во-вторых,\n",
    "                      Кашу в норме прочной.\n",
    "                      Нет, старик он был старик\n",
    "                      Чуткий - это точно.\n",
    "'''\n",
    "\n",
    "slova=re.findall(r\"\\b[a-zA-Zа-яА-ЯёЁ]+(?:[-][a-zA-Zа-яА-ЯёЁ]+)*\\b\",text)\n",
    "print(len(slova))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задачка про поиск слов на а и на е"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите в тексте слова, начинающиеся на а и на е"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['example',\n",
       " 'an',\n",
       " 'ArrayList',\n",
       " 'a',\n",
       " 'elements',\n",
       " 'elements',\n",
       " 'are',\n",
       " 'added',\n",
       " 'ArrayList',\n",
       " 'and',\n",
       " 'ArrayList',\n",
       " 'accordingly']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# Input.\n",
    "text = \"The following example creates an ArrayList with a capacity of 50 elements.\\\n",
    "        Four elements are then added to the ArrayList and the ArrayList is trimmed accordingly.\"\n",
    "\n",
    "re.findall(r\"(?=\\b[Aa|Ee])\\b[a-zA-Z]+\\b\",text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример 2**\n",
    "\n",
    "Найдите в тексте слова, начинающиеся на а и на е"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['euch', 'einst', 'euch']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# Input.\n",
    "text = '''\n",
    "        Ihr naht euch wieder, schwankende Gestalten,\n",
    "        Die früh sich einst dem trüben Blick gezeigt.\n",
    "        Versuch’ ich wohl, euch diesmal festzuhalten?\n",
    "        Fühl’ ich mein Herz noch jenem Wahn geneigt?\n",
    "        '''\n",
    "re.findall(r\"(?=\\b[Aa|Ee])\\b[a-zA-Z’]+\\b\",text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задачка про деление текста на предложения "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для простоты будем считать, что: \n",
    "* каждое предложение начинается с заглавной русской или латинской буквы;\n",
    "* каждое предложение заканчивается одним из знаков препинания .;!?;\n",
    "* между предложениями может быть любой непустой набор пробельных символов;\n",
    "* внутри предложений нет заглавных и точек (нет пакостей в духе «Мы любим творчество А. С. Пушкина)».\n",
    "\n",
    "Разделите текст на предложения так, чтобы каждое предложение занимало одну строку. \n",
    "Пустых строк в выводе быть не должно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr.\n",
      "Smith bought cheapsite.com for 1.5 million dollars, i.e. he paid a lot for it!\n",
      "Did he mind?\n",
      "Adam Jones Jr. thinks he didn't.\n",
      "In any case, this isn't true...\n",
      "Well, with a probability of .9 it isn't.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "s = \"\"\"Mr. Smith bought cheapsite.com for 1.5 million dollars, i.e. he paid a lot for it! \\\n",
    "Did he mind? Adam Jones Jr. thinks he didn't. In any case, this isn't true... \\\n",
    "Well, with a probability of .9 it isn't.\"\"\"\n",
    "\n",
    "def find_sentenses(text):\n",
    "    pattern=r\"(\\W+)(\\s+)(\\b[A-ZА-ЯЁ])\"\n",
    "    repl=r\"\\1\\n\\3\"\n",
    "    return re.sub(pattern,repl,text)\n",
    "\n",
    "print(find_sentenses(s))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\kzolo/nltk_data'\n    - 'C:\\\\Users\\\\kzolo\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\kzolo\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\kzolo\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\kzolo\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-132-c1c66ae86551>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \"\"\"\n\u001b[1;32m--> 106\u001b[1;33m     \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tokenizers/punkt/{0}.pickle\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    750\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    751\u001b[0m     \u001b[1;31m# Load the resource.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 752\u001b[1;33m     \u001b[0mopened_resource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    753\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"raw\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"nltk\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 877\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    878\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"file\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[1;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\kzolo/nltk_data'\n    - 'C:\\\\Users\\\\kzolo\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\kzolo\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\kzolo\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\kzolo\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "s = \"\"\"Mr. Smith bought cheapsite.com for 1.5 million dollars, i.e. he paid a lot for it! \\\n",
    "Did he mind? Adam Jones Jr. thinks he didn't. In any case, this isn't true... \\\n",
    "Well, with a probability of .9 it isn't.\"\"\"\n",
    "\n",
    "from nltk import sent_tokenize\n",
    "sentences = sent_tokenize(s)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Давайте разберем реальный пример\n",
    "\n",
    "Возьмем перевод книги Идиот, вытащим оттуда текст первой главы, после чего посчитаем количество вхождений слова the. Ссылка 'https://www.gutenberg.org/files/2638/2638-0.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "\n",
    "the_idiot_url = 'https://www.gutenberg.org/files/2638/2638-0.txt'\n",
    "raw = requests.get(the_idiot_url).text\n",
    "\n",
    "# Индекс начала первой главы\n",
    "start = re.search(r'\\*\\*\\* START OF THIS PROJECT GUTENBERG EBOOK THE IDIOT \\*\\*\\*', raw).end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25283"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Индекс конца первой главы\n",
    "end = re.search(r'II', raw).start()\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Про время\n",
    "Вовочка подготовил одно очень важное письмо, но везде указал неправильное время. \n",
    "Поэтому нужно заменить все вхождения времени на строку (TBD). Время — это строка вида HH:MM:SS или HH:MM, в которой HH — число от 00 до 23, а MM и SS — число от 00 до 59."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ввод:\n",
    "\n",
    "    Уважаемые! Если вы к 09:00 не вернёте \n",
    "    чемодан, то уже в 09:00:01 я за себя не отвечаю. \n",
    "    PS. С отношением 25:50 всё нормально!\n",
    "    \n",
    "Вывод:\n",
    "\n",
    "    Уважаемые! Если вы к (TBD) не вернёте \n",
    "    чемодан, то уже в (TBD) я за себя не отвечаю. \n",
    "    PS. С отношением 25:50 всё нормально!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = \"\"\"Уважаемые! Если вы к 09:00 не вернёте \n",
    "чемодан, то уже в 09:00:01 я за себя не отвечаю. \n",
    "PS. С отношением 25:50 всё нормально!\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Про финансовую отчетность\n",
    "\n",
    "Владимиру потребовалось срочно запутать финансовую документацию. Но так, чтобы это было обратимо. \n",
    "Он не придумал ничего лучше, чем заменить каждое целое число (последовательность цифр) на его куб. Помогите ему.\n",
    "\n",
    "Ввод:\n",
    "\n",
    "    Было закуплено 12 единиц техники \n",
    "    по 410.37 рублей.\n",
    "    \n",
    "Вывод:\n",
    "\n",
    "    Было закуплено 1728 единиц техники \n",
    "    по 68921000.50653 рублей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
